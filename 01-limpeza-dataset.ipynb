{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup das variáveis\n",
    "file_path = \"C:\\\\Projetos Python\\\\Fiap\\\\F3-tech-challenge\\\\LF-Amazon-1.3M\\\\trn.json\"\n",
    "output_path = \"C:\\\\Projetos Python\\\\Fiap\\\\F3-tech-challenge\\\\LF-Amazon-1.3M\\\\trn_tratado.json\"\n",
    "output_limited_path = \"C:\\\\Projetos Python\\\\Fiap\\\\F3-tech-challenge\\\\LF-Amazon-1.3M\\\\trn_tratado_limitado.json\"\n",
    "output_limited_jsonl_path = \"C:\\\\Projetos Python\\\\Fiap\\\\F3-tech-challenge\\\\LF-Amazon-1.3M\\\\trn_tratado_limitado.jsonl\"\n",
    "colunas_desejadas = ['title', 'content']\n",
    "num_lines = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passos:\n",
    " 1. Escolhendo Dataset\n",
    " 2. Preparação do Dataset - Limpeza do Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_lines(file_path, num_lines=None, usecols=None, content_column='content'):\n",
    "    \"\"\"\n",
    "    Lê um número específico de linhas de um arquivo JSON, ignora registros com conteúdo vazio e limpa caracteres especiais.\n",
    "\n",
    "    Parâmetros:\n",
    "    file_path (str): Caminho para o arquivo JSON.\n",
    "    num_lines (int, opcional): Número de linhas a serem lidas. Se omitido, lê o arquivo inteiro.\n",
    "    usecols (list, opcional): Lista de nomes de colunas a serem lidas. Se omitido, lê todas as colunas.\n",
    "    content_column (str, opcional): Nome da coluna a ser verificada para conteúdo vazio e limpeza. Padrão é 'content'.\n",
    "\n",
    "    Retorna:\n",
    "    pd.DataFrame: DataFrame contendo as linhas lidas, filtradas e limpas.\n",
    "    \"\"\"\n",
    "    if num_lines is None:\n",
    "        df = pd.read_json(file_path, lines=True)\n",
    "        if usecols:\n",
    "            df = df[usecols]\n",
    "        df = df[df[content_column].notna() & (df[content_column] != '')]\n",
    "        df[content_column] = df[content_column].apply(clean_text)\n",
    "        return df\n",
    "    else:\n",
    "        chunks = pd.read_json(file_path, lines=True, chunksize=num_lines)\n",
    "        for chunk in chunks:\n",
    "            if usecols:\n",
    "                chunk = chunk[usecols]\n",
    "            chunk = chunk[chunk[content_column].notna() & (chunk[content_column] != '')]\n",
    "            chunk[content_column] = chunk[content_column].apply(clean_text)\n",
    "            if not chunk.empty:\n",
    "                return chunk\n",
    "        return pd.DataFrame()  # Retorna um DataFrame vazio se nenhum chunk válido for encontrado\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_json(df, output_path):\n",
    "    \"\"\"\n",
    "    Salva o DataFrame em um arquivo JSON.\n",
    "\n",
    "    Parâmetros:\n",
    "    df (pd.DataFrame): DataFrame a ser salvo.\n",
    "    output_path (str): Caminho para o arquivo de saída.\n",
    "    \"\"\"\n",
    "    df.to_json(output_path, orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Remove entidades HTML e caracteres especiais de um texto.\n",
    "\n",
    "    Parâmetros:\n",
    "    text (str): Texto a ser limpo.\n",
    "\n",
    "    Retorna:\n",
    "    str: Texto limpo.\n",
    "    \"\"\"\n",
    "    if isinstance(text, str):\n",
    "        # Decodifica entidades HTML\n",
    "        text = html.unescape(text)\n",
    "        # Remove caracteres especiais, mantendo letras, números e espaços\n",
    "        cleaned_text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return cleaned_text\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpeza do dataframe original\n",
    "df_tradado = read_json_lines(file_path, None, usecols=colunas_desejadas)\n",
    "save_json(df_tradado, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limitar o número de linhas json para usar no modelo\n",
    "df_tradado_limitado = read_json_lines(output_path, num_lines, None)\n",
    "save_json(df_tradado_limitado, output_limited_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total de linhas do arquivo original\n",
    "tamanho_original = len(pd.read_json(file_path, lines=True))\n",
    "tamanho_tratado = len(df_tradado)\n",
    "tamanho_tratado_limitado = len(df_tradado_limitado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A leitura de '2248619' linhas do arquivo 'C:\\Projetos Python\\Fiap\\F3-tech-challenge\\LF-Amazon-1.3M\\trn.json'\n",
      "Resultaram em '1498718' linhas salvas no 'C:\\Projetos Python\\Fiap\\F3-tech-challenge\\LF-Amazon-1.3M\\trn_tratado.json'.\n",
      "Isso representa '66.65%' do arquivo original.\n",
      "Dataframe final:\n",
      "'1000' ('0.04%') linhas salvas no 'C:\\Projetos Python\\Fiap\\F3-tech-challenge\\LF-Amazon-1.3M\\trn_tratado_limitado.json'.\n"
     ]
    }
   ],
   "source": [
    "# Resultado da limpeza dos dados\n",
    "# Limpeza feita:\n",
    "# - Remoção de registros com conteúdo vazio\n",
    "# - Leitura de um número específico de linhas\n",
    "# - Limpar códigos HTML e caracteres especiais\n",
    "# - Ignorar colunas que não serão usadas\n",
    "print(f\"A leitura de '{tamanho_original}' linhas do arquivo '{file_path}'\")\n",
    "print(f\"Resultaram em '{len(df_tradado)}' linhas salvas no '{output_path}'.\")\n",
    "porc_linhas = (tamanho_tratado / tamanho_original) * 100\n",
    "print(f\"Isso representa '{porc_linhas:.2f}%' do arquivo original.\")\n",
    "print(f\"Dataframe final:\")\n",
    "porc_linhas_limitado = (tamanho_tratado_limitado / tamanho_original) * 100\n",
    "print(f\"'{tamanho_tratado_limitado}' ('{porc_linhas_limitado:.2f}%') linhas salvas no '{output_limited_path}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo .jsonl criado com sucesso: C:\\Projetos Python\\Fiap\\F3-tech-challenge\\LF-Amazon-1.3M\\trn_tratado_limitado.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def convert_json_to_jsonl(input_file, output_file):\n",
    "    \"\"\"\n",
    "    Converte um arquivo contendo objetos JSON separados por nova linha em um arquivo .jsonl.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Caminho para o arquivo de entrada contendo objetos JSON separados por nova linha.\n",
    "        output_file (str): Caminho para o arquivo .jsonl de saída.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(input_file, 'r') as f_in, open(output_file, 'w') as f_out:\n",
    "            for line in f_in:\n",
    "                line = line.strip()\n",
    "                if line:  # Verifica se a linha não está vazia\n",
    "                    try:\n",
    "                        obj = json.loads(line)\n",
    "                        json.dump(obj, f_out)\n",
    "                        f_out.write('\\n')\n",
    "                    except json.JSONDecodeError:\n",
    "                        print(f\"Aviso: Linha inválida encontrada no arquivo {input_file}: {line}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Erro: Arquivo de entrada não encontrado: {input_file}\")\n",
    "\n",
    "# Exemplo de uso\n",
    "input_file = 'seu_arquivo_de_entrada.json'  # Substitua pelo caminho do seu arquivo de entrada\n",
    "output_file = 'seu_arquivo_de_saida.jsonl'\n",
    "\n",
    "convert_json_to_jsonl(output_limited_path, output_limited_jsonl_path)\n",
    "\n",
    "print(f\"Arquivo .jsonl criado com sucesso: {output_limited_jsonl_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
